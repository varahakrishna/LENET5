{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xv5POrcNAXD5"},"outputs":[],"source":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"uM3ZK98qhW1N","executionInfo":{"status":"ok","timestamp":1684441254400,"user_tz":300,"elapsed":16923,"user":{"displayName":"Varaha Krishna","userId":"09050244137550246252"}},"outputId":"288920b9-2232-4212-e2ba-2b8ddde357fa","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"ReU1XW2jBaNt","executionInfo":{"status":"ok","timestamp":1684439577533,"user_tz":300,"elapsed":26975,"user":{"displayName":"Varaha Krishna","userId":"09050244137550246252"}}},"outputs":[],"source":["# Load in relevant libraries, and alias where appropriate\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","from tensorflow.keras.datasets import mnist\n","import random\n","\n","# Define relevant variables for the ML task\n","batch = 64\n","classes_num = 10\n","lrn_rt = 0.001\n","num_epochs = 10\n","\n","# Device will determine whether to run the training on GPU or CPU.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R8sJ7C2JBvJ0"},"outputs":[],"source":["#Loading the dataset and preprocessing\n","train_dataset = torchvision.datasets.MNIST(root = './data',\n","                                           train = True,\n","                                           transform = transforms.Compose([\n","                                                  transforms.Resize((32,32)),\n","                                                  transforms.ToTensor(),\n","                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n","                                           download = True)\n","\n","\n","test_dataset = torchvision.datasets.MNIST(root = './data',\n","                                          train = False,\n","                                          transform = transforms.Compose([\n","                                                  transforms.Resize((32,32)),\n","                                                  transforms.ToTensor(),\n","                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n","                                          download=True)\n","\n","\n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","                                           batch_size = batch,\n","                                           shuffle = True)\n","\n","\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n","                                           batch_size = batch,\n","                                           shuffle = True)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Oadox9C7B1vj","executionInfo":{"status":"ok","timestamp":1684439585919,"user_tz":300,"elapsed":129,"user":{"displayName":"Varaha Krishna","userId":"09050244137550246252"}}},"outputs":[],"source":["#Defining the convolutional neural network\n","class LeNet5(nn.Module):\n","    def __init__(self, classes_num):\n","        super(LeNet5, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0)\n","        self.bn1 = nn.BatchNorm2d(6)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0)\n","        self.bn2 = nn.BatchNorm2d(16)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        self.fc1 = nn.Linear(400, 120)\n","        self.relu3 = nn.ReLU()\n","        self.fc2 = nn.Linear(120, 84)\n","        self.relu4 = nn.ReLU()\n","        self.fc3 = nn.Linear(84, classes_num)\n","        \n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu1(out)\n","        out = self.pool1(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu2(out)\n","        out = self.pool2(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc1(out)\n","        out = self.relu3(out)\n","        out = self.fc2(out)\n","        out = self.relu4(out)\n","        out = self.fc3(out)\n","        return out"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"keBG6JzSB64v","executionInfo":{"status":"ok","timestamp":1684439588616,"user_tz":300,"elapsed":402,"user":{"displayName":"Varaha Krishna","userId":"09050244137550246252"}}},"outputs":[],"source":["model = LeNet5(classes_num).to(device)\n","\n","#Setting the loss function\n","cost = nn.CrossEntropyLoss()\n","\n","#Setting the optimizer with the model parameters and learning rate\n","optimizer = torch.optim.Adam(model.parameters(), lr=lrn_rt)\n","\n","#this is defined to print how many steps are remaining when training\n","total_step = len(train_loader)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o0miKbC6CEaE","outputId":"c77a04db-bdd9-459b-f11c-2d4ae8982e38","executionInfo":{"status":"ok","timestamp":1684440014826,"user_tz":300,"elapsed":424230,"user":{"displayName":"Varaha Krishna","userId":"09050244137550246252"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Step [400/938], Loss: 0.0403\n","Epoch [1/10], Step [800/938], Loss: 0.1967\n","Epoch [2/10], Step [400/938], Loss: 0.0878\n","Epoch [2/10], Step [800/938], Loss: 0.0597\n","Epoch [3/10], Step [400/938], Loss: 0.0181\n","Epoch [3/10], Step [800/938], Loss: 0.0206\n","Epoch [4/10], Step [400/938], Loss: 0.0137\n","Epoch [4/10], Step [800/938], Loss: 0.0030\n","Epoch [5/10], Step [400/938], Loss: 0.0162\n","Epoch [5/10], Step [800/938], Loss: 0.0055\n","Epoch [6/10], Step [400/938], Loss: 0.0010\n","Epoch [6/10], Step [800/938], Loss: 0.0700\n","Epoch [7/10], Step [400/938], Loss: 0.0005\n","Epoch [7/10], Step [800/938], Loss: 0.0263\n","Epoch [8/10], Step [400/938], Loss: 0.0128\n","Epoch [8/10], Step [800/938], Loss: 0.0008\n","Epoch [9/10], Step [400/938], Loss: 0.0027\n","Epoch [9/10], Step [800/938], Loss: 0.1931\n","Epoch [10/10], Step [400/938], Loss: 0.0060\n","Epoch [10/10], Step [800/938], Loss: 0.0004\n"]}],"source":["total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):  \n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        #Forward pass\n","        outputs = model(images)\n","        loss = cost(outputs, labels)\n","        \t\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \t\t\n","        if (i+1) % 400 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","        \t\t           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6R495RqUCLLc"},"outputs":[],"source":["# Test the model\n","# In test phase, we don't need to compute gradients (for memory efficiency)\n","  \n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        \n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n","\t "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddpARUnVNh_d"},"outputs":[],"source":["\n","\n","# Evaluate the model on the test set\n","model.eval()\n","y_true = []\n","y_pred = []\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        y_true += labels.cpu().numpy().tolist()\n","        y_pred += predicted.cpu().numpy().tolist()\n","\n","# Print confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","print('Confusion matrix:\\n', cm)\n","\n","# Print classification report\n","target_names = ['Class {}'.format(i) for i in range(classes_num)]\n","print('Classification report:\\n', classification_report(y_true, y_pred, target_names=target_names))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tV_kgy25TwdL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7yk90u-P888"},"outputs":[],"source":["\n","# get the predictions on the test set\n","with torch.no_grad():\n","    y_true = []\n","    y_pred = []\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        y_true += labels.cpu().numpy().tolist()\n","        y_pred += predicted.cpu().numpy().tolist()\n","\n","# compute the confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","\n","# plot the confusion matrix\n","fig, ax = plt.subplots(figsize=(10, 10))\n","im = ax.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n","ax.figure.colorbar(im, ax=ax)\n","classes = np.arange(10)\n","ax.set(xticks=np.arange(conf_matrix.shape[1]),\n","       yticks=np.arange(conf_matrix.shape[0]),\n","       xticklabels=classes, yticklabels=classes,\n","       xlabel='Predicted label',\n","       ylabel='True label',\n","       title='Confusion matrix')\n","plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","         rotation_mode=\"anchor\")\n","fmt = '.2f' \n","thresh = conf_matrix.max() / 2.\n","for i in range(conf_matrix.shape[0]):\n","    for j in range(conf_matrix.shape[1]):\n","        ax.text(j, i, format(conf_matrix[i, j], fmt),\n","                ha=\"center\", va=\"center\",\n","                color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n","fig.tight_layout()\n","plt.show()\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dagJKMK1PTwp"},"outputs":[],"source":["\n","\n","# initialize lists to store losses and epochs\n","train_losses = []\n","epochs = range(1, num_epochs+1)\n","\n","# iterate through each epoch and collect the loss\n","for epoch in epochs:\n","    train_loss = 0.0\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        loss = cost(outputs, labels)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    # calculate and store the average loss for each epoch\n","    train_losses.append(train_loss / len(train_loader))\n","\n","# plot the loss vs epochs graph\n","plt.plot(epochs, train_losses, label='Training Loss')\n","plt.title('Loss vs Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HagAEbXHW_vX"},"outputs":[],"source":["\n","\n","# Load MNIST dataset\n","(train_X, train_y), (test_X, test_y) = mnist.load_data()\n","\n","# Count number of images in each class\n","class_counts = np.bincount(train_y)\n","\n","# Plot bar graph of class distribution\n","plt.bar(range(10), class_counts)\n","plt.xticks(range(10), labels=[str(i) for i in range(10)])\n","plt.xlabel('Class')\n","plt.ylabel('Number of Images')\n","plt.title('MNIST Class Distribution')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YKw41BakXAG3"},"outputs":[],"source":["# Plot histogram of pixel intensity values\n","plt.hist(train_X.flatten(), bins=256, range=(0, 255))\n","plt.xlabel('Pixel Intensity')\n","plt.ylabel('Frequency')\n","plt.title('MNIST Pixel Intensity Distribution')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b2oqbb7yXwP8"},"outputs":[],"source":["\n","# Plot random sample of 25 images\n","fig, ax = plt.subplots(5, 5, figsize=(8, 8))\n","ax = ax.flatten()\n","for i in range(25):\n","    img_index = random.randint(0, len(train_X))\n","    ax[i].imshow(train_X[img_index], cmap='gray')\n","    ax[i].set_title(f'Label: {train_y[img_index]}')\n","    ax[i].axis('off')\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}